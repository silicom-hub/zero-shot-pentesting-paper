import argparse
from transformers import pipeline

import sys
sys.path.append("./")

from envs.nasim import Env_Nasim
from benchmark import Benchmark


def main(agent, env, benchmark):

	env.reset()
	episode_return = 0

	done = False

	while done == False:

		# Decide of the target
		best_target = None
		sequence_to_classify = env.description_goal

		candidate_ip = []
		candidate_labels = []
		for ip in env.memory_env.keys():

			candidate_ip.append(ip)
			if ip in env.privilege_on_progress:
				if ip in env.exploit_target_failed:
					# candidate_labels.append("Continue to attack %s and get arrested" % env.ip_to_id[ip])
					# candidate_labels.append("%s has been already attacked but has been arrested" % env.ip_to_id[ip])
					# candidate_labels.append("%s has already been attacked but the last attack was stopped" % env.ip_to_id[ip])
					candidate_labels.append("%s is a dead end" % env.ip_to_id[ip])
				else:
					# candidate_labels.append("Continue to attack %s" % env.ip_to_id[ip])
					candidate_labels.append("%s has already been attacked" % env.ip_to_id[ip])

			elif ip in env.privilege_obtain:
				# candidate_labels.append("You cannot obtain more privilege on %s" % env.ip_to_id[ip])
				# candidate_labels.append("Finish to attack %s" % env.ip_to_id[ip])
				candidate_labels.append("%s is totally corrupted" % env.ip_to_id[ip])

			elif ip in env.privilege_cannot_be_obtain:
				# candidate_labels.append("You cannot obtain more privilege on %s" % env.ip_to_id[ip])
				# candidate_labels.append("Finish to attack %s" % env.ip_to_id[ip])
				candidate_labels.append("%s is totally corrupted" % env.ip_to_id[ip])

			elif ip in env.nasim.network.get_sensitive_hosts():
				# candidate_labels.append("%s is one of the target machine." % env.ip_to_id[ip])
				candidate_labels.append("%s is one of the target machine." % env.ip_to_id[ip])

			else:
				# candidate_labels.append("%s is a new machine" % env.ip_to_id[ip])
				# candidate_labels.append("Start to attack %s" % env.ip_to_id[ip])
				candidate_labels.append("%s is a new machine" % env.ip_to_id[ip])

		if len(candidate_labels) != len(candidate_ip):
			raise NotImplementedError

		print("="*100)
		print("Description:")
		print(sequence_to_classify)
		print("Target possible:")
		for label in candidate_labels:
			print(label)

		pred = classifier(sequence_to_classify, candidate_labels)

		for label, ip in zip(candidate_labels, candidate_ip):
			if pred["labels"][0] == label:
				best_target = ip

		if best_target == None:
			raise NotImplementedError

		best_action = None
		best_id_action = -1
		best_pred = 0.0

		sequence_to_classify = env.context[best_target]
		candidate_labels = env.actions_runnable[best_target]

		print("="*100)
		print("Context:")
		print(sequence_to_classify)
		print("="*100)
		print("Action:")
		for label in candidate_labels:
			print(label)
		print("="*100)
		print("\n\n")
		pred = classifier(sequence_to_classify, candidate_labels)
		best_action = pred["labels"][0]
		best_pred = pred["scores"][0]

		for i in range(0, len(candidate_labels)):
			if best_action ==  candidate_labels[i]:
				best_id_action = i
				break

		if best_id_action == -1:
			raise NotImplementedError

		act_id = env.id_to_action[best_target][best_id_action]

		# state, reward, done, step_limit, info = env.step(act_id)
		state, reward, done, info = env.step(act_id)

		episode_return += reward
		print("Id: %d, Target: %s, Action: %s, Proba: %.2f, Status: %d" % (act_id, best_target, best_action, best_pred, info["success"]))

	print("Episode return: %d" % episode_return)

	benchmark.add_new_experiment(env.env_name, "zero-shot", episode_return)


if __name__ == "__main__":

	parser = argparse.ArgumentParser()
	parser.add_argument("--env", type=str, default="custom", help="the name of the environment")

	args = parser.parse_args()

	benchmark = Benchmark("output/results_test_v6.json")
	classifier = pipeline("zero-shot-classification", model="facebook/bart-large-mnli")

	# env = Env_Nasim(args.env, mode="eval")
	env = Env_Nasim(args.env)

	#benchmark.reset_experiments(args.env, "zero-shot")
	for _ in range(0, 1):
		main(classifier, env, benchmark)

	benchmark.update_scores()
	benchmark.render()
	benchmark.save()
